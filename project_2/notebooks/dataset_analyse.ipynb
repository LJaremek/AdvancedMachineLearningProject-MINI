{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.int = np.int32\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_\n",
    "\n",
    "from boruta import BorutaPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(file_name: str, features: list[tuple[str, float]]) -> None:\n",
    "    with open(f\"{file_name}.txt\", \"w\") as file:\n",
    "        for feature in features:\n",
    "            print(feature[0], file=file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5000, 500)\n",
      "Y shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "x_train_path = \"../data/x_train.txt\"\n",
    "y_train_path = \"../data/y_train.txt\"\n",
    "\n",
    "x_data = np.loadtxt(x_train_path, delimiter=' ')\n",
    "y_data = np.loadtxt(y_train_path, delimiter=' ')\n",
    "\n",
    "print(\"X shape:\", x_data.shape)\n",
    "print(\"Y shape:\", y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y == 1: 2496\n",
      "Y == 0: 2504\n"
     ]
    }
   ],
   "source": [
    "print(\"Y == 1:\", sum([1 for record in y_data if record == 1]))\n",
    "print(\"Y == 0:\", sum([1 for record in y_data if record == 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "standard_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data_standardized = standard_scaler.fit_transform(x_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X polynomialed shape: (5000, 125751)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polunomial_builder = PolynomialFeatures()\n",
    "x_df_poly = polunomial_builder.fit_transform(x_data_standardized)\n",
    "\n",
    "print(\"X polynomialed shape:\", x_df_poly.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_names = [f\"feature {i}\" for i in range(x_data_standardized.shape[1])]\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(x_data_standardized, y_data)\n",
    "feature_importances = forest.feature_importances_\n",
    "\n",
    "forest_importances = {\n",
    "    feature_names[i]: feature_importances[i]\n",
    "    for i in range(len(feature_names))\n",
    "}\n",
    "\n",
    "sorted_features = sorted(\n",
    "    forest_importances.items(),\n",
    "    key=lambda x:x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "the_best_features = sorted_features[:20]\n",
    "\n",
    "save_features(f\"standarized_rfc_{len(the_best_features)}\", the_best_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomialed RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_names = [f\"feature {i}\" for i in range(x_df_poly.shape[1])]\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(x_df_poly, y_data)\n",
    "feature_importances = forest.feature_importances_\n",
    "\n",
    "forest_importances = {\n",
    "    feature_names[i]: feature_importances[i]\n",
    "    for i in range(len(feature_names))\n",
    "}\n",
    "\n",
    "sorted_features = sorted(\n",
    "    forest_importances.items(),\n",
    "    key=lambda x:x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "the_best_features = sorted_features[:20]\n",
    "\n",
    "save_features(f\"polynomialed_rfc_{len(the_best_features)}\", the_best_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\")\n",
    "boruta_model = BorutaPy(rf, n_estimators=\"auto\")\n",
    "boruta_model.fit(x_data_standardized, y_data)\n",
    "\n",
    "feature_names = [f\"feature {i}\" for i in range(x_data_standardized.shape[1])]\n",
    "feature_importances = boruta_model.support_\n",
    "\n",
    "the_best_features = [\n",
    "    (feature_names[i], 1.0)\n",
    "    for i in range(len(feature_names))\n",
    "    if feature_importances[i] == True\n",
    "]\n",
    "\n",
    "save_features(\n",
    "    f\"standarized_boruta_{len(the_best_features)}\",\n",
    "    the_best_features\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "select_k_best = SelectKBest(score_func=f_classif, k=10)\n",
    "X_new = select_k_best.fit_transform(x_data_standardized, y_data)\n",
    "selected_features_kbest = select_k_best.get_support(indices=True)\n",
    "selected_features_names_kbest = [(f\"feature {i}\", 1) for i in selected_features_kbest]\n",
    "\n",
    "save_features(\n",
    "    f\"standarized_kbest_{len(the_best_features)}\",\n",
    "    the_best_features\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(x_data_standardized, y_data)\n",
    "selected_features_lasso = np.where(lasso.coef_ != 0)[0]\n",
    "selected_features_names_lasso = [f\"feature {i}\" for i in selected_features_lasso]\n",
    "\n",
    "save_features(\n",
    "    f\"standarized_lasso_{len(the_best_features)}\",\n",
    "    the_best_features\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
