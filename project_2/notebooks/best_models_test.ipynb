{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a synthetic dataset\n",
    "# with open('./reduced_data/X_boruta_cfs.pickle', 'rb') as handle:\n",
    "#     X = pickle.load(handle)\n",
    "\n",
    "columns = [101, 102, 103, 105]\n",
    "X = np.loadtxt(\"../data/x_train.txt\", delimiter=' ')\n",
    "X = X[:, columns]\n",
    "y = np.loadtxt(\"../data/y_train.txt\", delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_state = random.randint(0, 300)\n",
    "random_state = 145\n",
    "random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.628      0.61965812 0.60887097 0.68076923 0.61811024 0.61788618\n",
      " 0.62601626 0.5936255  0.64150943 0.66528926]\n",
      "Mean cross-validation score:  0.629973518158273\n",
      "Results saved to random_forest_2024-05-29_16-08-06.json\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_save_random_forest(X, y, params=None, n_splits=10, random_state=42, scoring='recall', filename='random_forest_'):\n",
    "    # Default parameters if none are provided\n",
    "    if params is None:\n",
    "    # Parameters for the Random Forest\n",
    "        params = OrderedDict(\n",
    "            [('n_estimators', 59), \n",
    "            ('max_depth', 20), \n",
    "            ('min_samples_split', 10)])\n",
    "\n",
    "    # Create the Random Forest model with the specified parameters\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Set up k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(rf_model, X, y, cv=kf, scoring=scoring)\n",
    "    \n",
    "    # Calculate mean cross-validation score\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Prepare results to save\n",
    "    results = {\n",
    "        'columns': columns,\n",
    "        'params': params,\n",
    "        'n_splits': n_splits,\n",
    "        'random_state': random_state,\n",
    "        'scoring': scoring,\n",
    "        'cv_scores': cv_scores.tolist(),\n",
    "        'mean_cv_score': mean_cv_score\n",
    "    }\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs('results_best_models', exist_ok=True)\n",
    "\n",
    "    # Get current date and hour\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    filename = filename + current_time + '.json'\n",
    "    \n",
    "    # Save results to file\n",
    "    with open('results_best_models/' + filename, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "    \n",
    "    print(\"Cross-validation scores: \", cv_scores)\n",
    "    print(\"Mean cross-validation score: \", mean_cv_score)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "# Example usage:\n",
    "evaluate_and_save_random_forest(X, y, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.636      0.61538462 0.625      0.63461538 0.61811024 0.62601626\n",
      " 0.62601626 0.59760956 0.63396226 0.64049587]\n",
      "Mean cross-validation score:  0.6253210450218203\n",
      "Results saved to xgbrf_2024-05-29_16-08-12.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_and_save_xgbrf(X, y, params=None, n_splits=10, random_state=42, scoring='recall', filename='xgbrf_'):\n",
    "    # Default parameters if none are provided\n",
    "    if params is None:\n",
    "        params = OrderedDict(\n",
    "            [('learning_rate', 0.9149030789798307), \n",
    "             ('max_depth', 17), \n",
    "             ('n_estimators', 80), \n",
    "             ('subsample', 0.5)]\n",
    "        )\n",
    "    \n",
    "    # Create the XGBoost Random Forest model with the specified parameters\n",
    "    xgbrf_model = XGBRFClassifier(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=params['max_depth'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        subsample=params['subsample'],\n",
    "        use_label_encoder=False, \n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    # Set up k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(xgbrf_model, X, y, cv=kf, scoring=scoring)\n",
    "    \n",
    "    # Calculate mean cross-validation score\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Prepare results to save\n",
    "    results = {\n",
    "        'columns': columns,\n",
    "        'params': params,\n",
    "        'n_splits': n_splits,\n",
    "        'random_state': random_state,\n",
    "        'scoring': scoring,\n",
    "        'cv_scores': cv_scores.tolist(),\n",
    "        'mean_cv_score': mean_cv_score\n",
    "    }\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs('results_best_models', exist_ok=True)\n",
    "\n",
    "    # Get current date and hour\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    filename = filename + current_time + '.json'\n",
    "    \n",
    "    # Save results to file\n",
    "    with open('results_best_models/' + filename, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "    \n",
    "    print(\"Cross-validation scores: \", cv_scores)\n",
    "    print(\"Mean cross-validation score: \", mean_cv_score)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "# Example usage:\n",
    "evaluate_and_save_xgbrf(X, y, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.684      0.64957265 0.64112903 0.69615385 0.66141732 0.66260163\n",
      " 0.66260163 0.64143426 0.64150943 0.70661157]\n",
      "Mean cross-validation score:  0.6647031370010132\n",
      "Results saved to xgboost_2024-05-29_16-08-15.json\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_save_xgboost(X, y, params=None, n_splits=10, random_state=42, scoring='recall', filename='xgboost_'):\n",
    "    # Default parameters if none are provided\n",
    "    if params is None:\n",
    "        params = OrderedDict(\n",
    "            [('learning_rate', 0.005169944690299296), \n",
    "            ('max_depth', 40), \n",
    "            ('n_estimators', 100), \n",
    "            ('subsample', 0.1)]\n",
    "        )\n",
    "\n",
    "# Create the Random Forest model with the specified parameters\n",
    "    xgb_model = XGBClassifier(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=params['max_depth'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        subsample=params['subsample'],\n",
    "        use_label_encoder=False, \n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Set up k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(xgb_model, X, y, cv=kf, scoring=scoring)\n",
    "    \n",
    "    # Calculate mean cross-validation score\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Prepare results to save\n",
    "    results = {\n",
    "        'columns': columns,\n",
    "        'params': params,\n",
    "        'n_splits': n_splits,\n",
    "        'random_state': random_state,\n",
    "        'scoring': scoring,\n",
    "        'cv_scores': cv_scores.tolist(),\n",
    "        'mean_cv_score': mean_cv_score\n",
    "    }\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs('results_best_models', exist_ok=True)\n",
    "\n",
    "    # Get current date and hour\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    filename = filename + current_time + '.json'\n",
    "    \n",
    "    # Save results to file\n",
    "    with open('results_best_models/' + filename, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "    \n",
    "    print(\"Cross-validation scores: \", cv_scores)\n",
    "    print(\"Mean cross-validation score: \", mean_cv_score)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "# Example usage:\n",
    "evaluate_and_save_xgboost(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Trash but maybe useful later**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_and_save_model(X, y, model_class, params=None, n_splits=10, random_state=42, scoring='recall', filename_prefix='model_'):\n",
    "\n",
    "    # Create the model with the specified parameters\n",
    "    model = model_class(**params) if params else model_class()\n",
    "    \n",
    "    # Set up k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf, scoring=scoring)\n",
    "    \n",
    "    # Calculate mean cross-validation score\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Prepare results to save\n",
    "    results = {\n",
    "        'model_class': model_class.__name__,\n",
    "        'params': params,\n",
    "        'n_splits': n_splits,\n",
    "        'random_state': random_state,\n",
    "        'scoring': scoring,\n",
    "        'cv_scores': cv_scores.tolist(),\n",
    "        'mean_cv_score': mean_cv_score\n",
    "    }\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs('results_best_models', exist_ok=True)\n",
    "\n",
    "    # Get current date and time\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    filename = filename_prefix + current_time + '.json'\n",
    "    \n",
    "    # Save results to file\n",
    "    with open('results_best_models/' + filename, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "    \n",
    "    print(\"Cross-validation scores: \", cv_scores)\n",
    "    print(\"Mean cross-validation score: \", mean_cv_score)\n",
    "    print(f\"Results saved to results_best_models/{filename}\")\n",
    "\n",
    "# Example usage:\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# params = OrderedDict([\n",
    "#     ('n_estimators', 100), \n",
    "#     ('max_depth', 10), \n",
    "#     ('min_samples_split', 5)\n",
    "# ])\n",
    "# evaluate_and_save_model(X, y, RandomForestClassifier, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
